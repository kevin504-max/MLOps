# Import required libraries
import pandas as pd  # For reading and handling tabular data
import matplotlib.pyplot as plt  # For plotting graphs
from sklearn.cluster import KMeans  # K-Means clustering algorithm
from sklearn.preprocessing import StandardScaler  # Data normalization

# 1. Load the data from the CSV file
# This file was generated by the ESP32 system, containing sensor readings.
df = pd.read_csv('merged.csv')  # Adjust the path if necessary

# 2. Select the relevant numeric columns
# We use only continuous numeric variables that influence the clustering process.
features = ['Temperature(C)', 'Humidity(%)', 'MQ4_PPM', 'MQ7_CO_PPM']
X = df[features]

# 3. Normalize the data
# Normalization is important so that all features have the same scale,
# preventing variables with larger magnitudes from dominating clustering.
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4. Apply the Elbow Method
# The elbow method helps determine the optimal number of clusters (K)
# by evaluating the Within-Cluster Sum of Squares (WSS or 'inertia') for different values of K.
wss = []  # List to store WSS values
k_range = range(1, 11)  # Try K from 1 to 10
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init='auto')  # random_state ensures reproducibility
    kmeans.fit(X_scaled)
    wss.append(kmeans.inertia_)  # .inertia_ stores the WSS value for the current K

# 5. Plot the Elbow Curve
# The goal is to find the "elbow point"â€”where the WSS starts decreasing more slowly.
# That point is usually a good choice for the optimal number of clusters.
plt.figure(figsize=(8, 5))
plt.plot(k_range, wss, 'bo-')  # 'bo-' means blue circles connected by lines
plt.xlabel('Number of clusters (K)')
plt.ylabel('WSS (inertia)')
plt.title('Elbow Method for K-Means Clustering')
plt.grid(True)
plt.savefig("elbow_plot.png")  # Save the plot as an image for reports or later use